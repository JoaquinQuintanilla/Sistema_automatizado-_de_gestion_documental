# Proyecto de TÃ­tulo - Sistema Automatizado de GestiÃ³n Documental

## DescripciÃ³n

Este proyecto implementa un **sistema automatizado de gestiÃ³n documental** para la Municipalidad de ValparaÃ­so, utilizando tÃ©cnicas de **inteligencia artificial**.

El sistema permite digitalizar, clasificar y extraer informaciÃ³n clave de documentos municipales mediante modelos avanzados de **OCR** y **modelos de lenguaje a gran escala (LLMs)**. La soluciÃ³n se expone a travÃ©s de una **API REST**, generando resultados en formato JSON estructurado, cumpliendo con la Ley 21.180 sobre TransformaciÃ³n Digital del Estado.

## TecnologÃ­as Utilizadas

- **Framework API**: FastAPI  
- **OCR**: Tesseract, EasyOCR, PaddleOCR, Donut (opcional)  
- **LLMs**: LLaMA 3, Mistral, DeepSeek, Qwen, Gemma  
- **Gestor de Dependencias**: pip / virtualenv  
- **Control de Versiones**: Git  
- **Motor de LLMs local**: Ollama  
- **MetodologÃ­a**: Scrum  

## Estructura del Proyecto

```
proyecto_titulo/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/               # Endpoints y modelos de entrada/salida
â”‚   â”œâ”€â”€ core/              # Configuraciones y logger
â”‚   â”œâ”€â”€ services/          # ImplementaciÃ³n de OCRs y LLMs
â”‚   â””â”€â”€ utils/             # MÃ©tricas y utilidades
â”œâ”€â”€ models/                # Archivos de configuraciÃ³n de modelos Ollama
â”œâ”€â”€ tests/                 # Pruebas unitarias
â”œâ”€â”€ resultados/graficos/  # Visualizaciones generadas por Jupyter
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

## InstalaciÃ³n y ConfiguraciÃ³n

```bash
git clone https://github.com/usuario/proyecto_titulo.git
cd proyecto_titulo
python -m venv venv
source venv/bin/activate  # O venv\Scripts\activate en Windows
pip install -r requirements.txt
```

## EjecuciÃ³n

```bash
uvicorn app.main:app --reload
```

- DocumentaciÃ³n Swagger: [http://localhost:8000/docs](http://localhost:8000/docs)

---

## Resultados y EvaluaciÃ³n

Se evaluaron 15 combinaciones posibles de OCR y LLM utilizando mÃ¡s de **9,000 documentos municipales**. A partir de los resultados recolectados se concluyÃ³ que:

- ğŸ” El **OCR mÃ¡s eficiente y preciso** es **PaddleOCR**, tanto en uso de CPU como en tiempo de ejecuciÃ³n.
- ğŸ§  Los **LLMs mÃ¡s eficientes en tiempo y precisiÃ³n** son **LLaMA 3.2 (3B)** y **Qwen2.5 (3B)**.
- ğŸ† Las **combinaciones mÃ¡s rÃ¡pidas** y con buen rendimiento global fueron:
  - `paddleocr_llama3`
  - `paddleocr_qwen`

AdemÃ¡s, se evaluÃ³ la capacidad de cada LLM para extraer clasificadores desde los documentos municipales, con un promedio de mÃ¡s de **13 clasificadores por documento** en los mejores modelos.

ğŸ“Š Para visualizar los resultados en detalle, consulta: [`README_graficos.md`](./resultados/graficos/README_graficos.md)

---

## ConstrucciÃ³n del Modelo LLaMA Municipal

```bash
cd models/llama3.2-municipal
ollama create llama3.2-municipal -f Modelfile
ollama run llama3.2-municipal
```

Este modelo personalizado fue optimizado para extraer metadatos estructurados desde documentos administrativos municipales en espaÃ±ol.

